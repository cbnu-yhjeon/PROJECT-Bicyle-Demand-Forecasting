
# Averaging / Voting ê¸°ë°˜ ì•™ìƒë¸” ê¸°ë²• ì„¤ëª… (ìˆ˜ì •ë³¸)

## 1. ì•™ìƒë¸”(Ensemble)ì´ë€?
ì•™ìƒë¸” í•™ìŠµì€ **ì—¬ëŸ¬ ê°œì˜ ê°œë³„ ëª¨ë¸(Base Learner)** ì„ ê²°í•©í•˜ì—¬  
ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ **ë” ì•ˆì •ì ì´ê³  ì¼ë°˜í™” ì„±ëŠ¥ì´ ë†’ì€ ì˜ˆì¸¡ ê²°ê³¼**ë¥¼ ì–»ëŠ” ê¸°ë²•ì´ë‹¤.

í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

> ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ì€ ì„œë¡œ ë‹¤ë¥¸ ê·€ë‚©ì  í¸í–¥(Inductive Bias)ê³¼ ì˜¤ë¥˜ íŒ¨í„´ì„ ê°€ì§„ë‹¤.  
> ì´ë“¤ì„ ê²°í•©í•˜ë©´ ê°œë³„ ëª¨ë¸ì˜ ì•½ì ì„ ìƒì‡„í•  ìˆ˜ ìˆë‹¤.

---

## 2. ë³¸ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•œ ì•™ìƒë¸” êµ¬ì¡°ì˜ ì „ì œ ì¡°ê±´

### 2.1 ì‹¤ì œ ëª¨ë¸ í•™ìŠµ êµ¬ì¡° (ì¤‘ìš”)
ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ì˜€ë‹¤.

```text
ì „ì²´ Feature Set (Time + POI + Weather)
 â”œâ”€ LightGBM
 â”œâ”€ XGBoost
 â””â”€ RandomForest
```

- ëª¨ë“  Base Modelì€ **ë™ì¼í•œ ì…ë ¥ í”¼ì²˜ ê³µê°„**ì„ ì‚¬ìš©
- ëª¨ë¸ ê°„ ì°¨ì´ëŠ” **ì•Œê³ ë¦¬ì¦˜ êµ¬ì¡°**ì—ë§Œ ì¡´ì¬
- ê° ëª¨ë¸ì€ **ë…ë¦½ì ìœ¼ë¡œ ë³‘ë ¬ í•™ìŠµ**

âš ï¸ ì¦‰, ë³¸ í”„ë¡œì íŠ¸ëŠ” **í”¼ì²˜ ë¶„í•  ê¸°ë°˜ ì•™ìƒë¸”ì´ ì•„ë‹˜**  
â†’ ì •í™•í•œ ë¶„ë¥˜ëŠ” **ëª¨ë¸ ë¶„í•  ê¸°ë°˜(Heterogeneous) ì•™ìƒë¸”**

---

## 3. Averaging / Voting ê³„ì—´ ì•™ìƒë¸” ê°œìš”

### 3.1 ì •ì˜
**Averaging / Voting Ensemble**ì€  
ì—¬ëŸ¬ ëª¨ë¸ì˜ **ì˜ˆì¸¡ ê²°ê³¼(prediction)** ë¥¼ ì§ì ‘ ê²°í•©í•˜ëŠ” ì•™ìƒë¸” ë°©ì‹ì´ë‹¤.

- ë¶„ë¥˜(Classification) â†’ Voting
- íšŒê·€(Regression) â†’ Averaging

ë³¸ í”„ë¡œì íŠ¸ëŠ” **ìì „ê±° ìˆ˜ìš” ì˜ˆì¸¡(íšŒê·€ ë¬¸ì œ)** ì´ë¯€ë¡œ  
*Averaging Ensemble*ì„ ì ìš©í•œë‹¤.

---

### 3.2 Averaging Ensemble ìˆ˜ì‹

Nê°œì˜ íšŒê·€ ëª¨ë¸ì´ ìˆì„ ë•Œ:

- ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’:  
  \( \hat{y}_1, \hat{y}_2, \dots, \hat{y}_N \)

#### (1) Simple Average
```math
\hat{y} = \frac{1}{N} \sum_{i=1}^{N} \hat{y}_i
```

#### (2) Weighted Average
```math
\hat{y} = \sum_{i=1}^{N} w_i \hat{y}_i, \quad \sum w_i = 1
```

ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” **Weighted Average Ensemble**ì„ ì‚¬ìš©í•œë‹¤.

---

## 4. Soft / Hard Voting ê³¼ì˜ ì°¨ì´

### 4.1 Hard Voting
- ê° ëª¨ë¸ì´ **ìµœì¢… í´ë˜ìŠ¤ ë¼ë²¨**ë§Œ íˆ¬í‘œ
- ë‹¤ìˆ˜ê²°ë¡œ ìµœì¢… ê²°ê³¼ ê²°ì •
- **ë¶„ë¥˜ ë¬¸ì œ ì „ìš©**

âŒ íšŒê·€ ë¬¸ì œì—ëŠ” ì ìš© ë¶ˆê°€  
â†’ ë³¸ í”„ë¡œì íŠ¸ì™€ ì§ì ‘ì ì¸ ê´€ë ¨ ì—†ìŒ

---

### 4.2 Soft Voting
- ê° ëª¨ë¸ì´ **í™•ë¥ ê°’(probability)** ì„ ì¶œë ¥
- í™•ë¥  í‰ê·  í›„ ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤ ì„ íƒ
- ë¶„ë¥˜ ë¬¸ì œì—ì„œ Hard Votingë³´ë‹¤ ì•ˆì •ì 

âŒ í™•ë¥  ì¶œë ¥ì´ ì „ì œ ì¡°ê±´  
âŒ íšŒê·€ ë¬¸ì œì—ëŠ” ê°œë…ì ìœ¼ë¡œ ë¶€ì í•©

---

### 4.3 Averaging (Regression Voting)
- ê° ëª¨ë¸ì´ **ì—°ì†ê°’ ì˜ˆì¸¡**
- ì˜ˆì¸¡ê°’ì„ ì§ì ‘ í‰ê· 

âœ” íšŒê·€ ë¬¸ì œì— ê°€ì¥ ìì—°ìŠ¤ëŸ½ê³  í‘œì¤€ì ì¸ ë°©ì‹  
âœ” ë³¸ í”„ë¡œì íŠ¸ì— ì •í™•íˆ ë¶€í•©

---

## 5. Stacking Ensembleê³¼ì˜ ì°¨ì´

### 5.1 Stacking êµ¬ì¡°
```text
ì „ì²´ Feature
 â”œâ”€ Base Model 1 â”€â”€â”
 â”œâ”€ Base Model 2 â”€â”€â”¼â”€â–¶ Meta Model â”€â–¶ ìµœì¢… ì˜ˆì¸¡
 â””â”€ Base Model 3 â”€â”€â”˜
```

- Base Model ì˜ˆì¸¡ê°’ì„ ì…ë ¥ìœ¼ë¡œ í•˜ëŠ” **Meta Model** í•™ìŠµ
- 2ë‹¨ê³„ í•™ìŠµ êµ¬ì¡°
- í‘œí˜„ë ¥ì€ ë†’ìœ¼ë‚˜ ë³µì¡ë„ ì¦ê°€

---

### 5.2 Averaging vs Stacking ë¹„êµ

| êµ¬ë¶„ | Averaging Ensemble | Stacking Ensemble |
|---|---|---|
| í•™ìŠµ ë‹¨ê³„ | 1ë‹¨ | 2ë‹¨ |
| êµ¬í˜„ ë³µì¡ë„ | ë‚®ìŒ | ë†’ìŒ |
| ë°ì´í„° ëˆ„ìˆ˜ ìœ„í—˜ | ê±°ì˜ ì—†ìŒ | ë†’ìŒ |
| í•´ì„ì„± | ë§¤ìš° ë†’ìŒ | ë‚®ìŒ |
| ì•ˆì •ì„± | ë§¤ìš° ë†’ìŒ | ì¤‘ê°„ |
| íŠœë‹ ë¹„ìš© | ë‚®ìŒ | ë†’ìŒ |

---

## 6. ì™œ Stackingì´ ì•„ë‹Œ Averagingì„ ì„ íƒí–ˆëŠ”ê°€?

### ì´ìœ  1ï¸âƒ£ ë°ì´í„° ëˆ„ìˆ˜ ë¦¬ìŠ¤í¬ ìµœì†Œí™”
- ì‹œê³„ì—´ ë°ì´í„° íŠ¹ì„±ìƒ  
  Stackingì€ **Validation Split ì„¤ê³„ê°€ ë§¤ìš° ê¹Œë‹¤ë¡œì›€**
- Averagingì€ í•™ìŠµ êµ¬ì¡°ê°€ ë‹¨ìˆœí•˜ì—¬ ëˆ„ìˆ˜ ìœ„í—˜ì´ ê±°ì˜ ì—†ìŒ

---

### ì´ìœ  2ï¸âƒ£ ëª¨ë¸ ë‹¤ì–‘ì„±ì€ ì•Œê³ ë¦¬ì¦˜ ì°¨ì´ë¡œ ì¶©ë¶„
- LGBM / XGB / RFëŠ” ëª¨ë‘ Tree ê³„ì—´ì´ì§€ë§Œ
- í•™ìŠµ ë°©ì‹ê³¼ ë¶„ê¸° ì „ëµì´ ì„œë¡œ ë‹¬ë¼ **ì¶©ë¶„í•œ ë‹¤ì–‘ì„± í™•ë³´**

---

### ì´ìœ  3ï¸âƒ£ í•´ì„ ê°€ëŠ¥ì„± (SHAP)
- ê° Base Modelì„ **ë…ë¦½ì ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥**
- Ensemble ë‹¨ê³„ëŠ” ë‹¨ìˆœ ê°€ì¤‘ í•© â†’ ì„¤ëª…ì´ ëª…í™•

---

### ì´ìœ  4ï¸âƒ£ í”„ë¡œì íŠ¸ ë‹¨ê³„ ì í•©ì„±
- ë³¸ í”„ë¡œì íŠ¸ëŠ”
  - ì‹¤í—˜ ì¬í˜„ì„±
  - ë³´ê³ ì„œ ë° ë°œí‘œ
  - ì•ˆì •ì ì¸ ì„±ëŠ¥
  ì„ ì¤‘ì‹œ

ğŸ‘‰ Averaging Ensembleì´ ê°€ì¥ í•©ë¦¬ì ì¸ ì„ íƒ

---

## 7. ë³¸ í”„ë¡œì íŠ¸ ì•™ìƒë¸”ì˜ ê³µì‹ ë¶„ë¥˜

- **Parallel Ensemble**
- **Heterogeneous Ensemble**
- **Model-based Ensemble**
- **Weighted Averaging Ensemble**

---

## 8. í•œ ë¬¸ì¥ ìš”ì•½ (ë³´ê³ ì„œìš©)

> *We employ a weighted averaging ensemble of heterogeneous tree-based regression models (LightGBM, XGBoost, and Random Forest), all trained on the same feature set, to improve prediction stability and generalization.*

---

## 9. í™•ì¥ ê°€ëŠ¥ì„±

- Validation ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ìµœì í™”
- SHAP ì¤‘ìš”ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
- í•„ìš” ì‹œ Stacking Ensembleë¡œ í™•ì¥ ê°€ëŠ¥

---

## 10. ìš”ì•½

- ë³¸ í”„ë¡œì íŠ¸ëŠ” **ëª¨ë¸ ë¶„í•  ê¸°ë°˜ Averaging Ensemble**
- Soft / Hard Votingê³¼ëŠ” ë¬¸ì œ ìœ í˜• ìì²´ê°€ ë‹¤ë¦„
- Stacking ëŒ€ë¹„ ì•ˆì •ì„±ê³¼ í•´ì„ì„±ì„ ìš°ì„ í•œ ì„¤ê³„
- í˜„ì¬ í”„ë¡œì íŠ¸ ë‹¨ê³„ì— ê°€ì¥ ì í•©í•œ ì•™ìƒë¸” ë°©ì‹
